# distilgpt2-followup-qg

In this project we train a language model (distilgpt2) on a small custom dataset, to generate follow-up questions for various user inputs.

With the limited samples in the custom dataset, a K-Fold cross validation technique was used, dividing the entire dataset into five subsets, to ensure the model generalized well.
