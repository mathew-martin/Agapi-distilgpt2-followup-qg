{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4968abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/follow_up_question_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1. Import libraries\n",
    "# -----------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import KFold \n",
    "import math\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1f6e18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2. Use GPU if available\n",
    "# -----------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "126a9ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# 3. Load and preprocess the dataset\n",
    "# ----------------------------------\n",
    "\n",
    "file_path = './data/follow_up_question_dataset.csv'\n",
    "dataset = load_dataset('csv', data_files=file_path)\n",
    "\n",
    "# Combine the Statement and Follow-Up Question into a single prompt, which is the input required for the distilgpt2 model\n",
    "def build_prompt(example):\n",
    "    prompt = f\"Statement: {example['statement']}\\nFollow-Up: {example['follow_up_question']}\"\n",
    "    return {\"text\": prompt}\n",
    "\n",
    "dataset = dataset.map(build_prompt) # apply the function to each example in the dataset\n",
    "\n",
    "model_name = \"distilgpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61c85b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.277300</td>\n",
       "      <td>2.864744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.396000</td>\n",
       "      <td>2.431613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.914900</td>\n",
       "      <td>2.185624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.537000</td>\n",
       "      <td>2.022842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.358400</td>\n",
       "      <td>1.951285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.121200</td>\n",
       "      <td>1.910924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.013100</td>\n",
       "      <td>1.884840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.945800</td>\n",
       "      <td>1.872361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.865100</td>\n",
       "      <td>1.868285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.835400</td>\n",
       "      <td>1.868440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5  •  val_loss = 1.8684\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.538400</td>\n",
       "      <td>3.185403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>2.990004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.713600</td>\n",
       "      <td>2.682733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.512900</td>\n",
       "      <td>2.578274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.398000</td>\n",
       "      <td>2.517755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.119700</td>\n",
       "      <td>2.466115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.114800</td>\n",
       "      <td>2.406915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.035200</td>\n",
       "      <td>2.350067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.920800</td>\n",
       "      <td>2.313144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.858500</td>\n",
       "      <td>2.298336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5  •  val_loss = 2.2983\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.452600</td>\n",
       "      <td>2.984812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.549400</td>\n",
       "      <td>2.503480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.928700</td>\n",
       "      <td>2.193488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.497200</td>\n",
       "      <td>2.017502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.318700</td>\n",
       "      <td>1.935356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.047300</td>\n",
       "      <td>1.887828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.940500</td>\n",
       "      <td>1.886858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>1.903714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.742700</td>\n",
       "      <td>1.923998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.728600</td>\n",
       "      <td>1.930981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5  •  val_loss = 1.9310\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.180500</td>\n",
       "      <td>2.729129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.153800</td>\n",
       "      <td>2.301623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.619600</td>\n",
       "      <td>2.125255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.271000</td>\n",
       "      <td>2.067447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.107500</td>\n",
       "      <td>2.043861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>2.059117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.786100</td>\n",
       "      <td>2.113421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.736100</td>\n",
       "      <td>2.132623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.683900</td>\n",
       "      <td>2.145864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>2.147092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5  •  val_loss = 2.1471\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.270300</td>\n",
       "      <td>2.538452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.181600</td>\n",
       "      <td>2.215488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.621000</td>\n",
       "      <td>2.067187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.295300</td>\n",
       "      <td>2.016674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.137700</td>\n",
       "      <td>1.991125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.887300</td>\n",
       "      <td>2.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>2.017766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.740400</td>\n",
       "      <td>2.045882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.648600</td>\n",
       "      <td>2.056655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.647700</td>\n",
       "      <td>2.062649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5  •  val_loss = 2.0626\n",
      "\n",
      "Cross-validated loss: 2.061499524116516 ± 0.153444492375097    (perplexity ≈ 7.857743856793563 )\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# 4. Training one fold\n",
    "# --------------------\n",
    "\n",
    "def train_one_fold(train_ds, val_ds, fold_id):\n",
    "    \"\"\"\n",
    "    Fine-tune DistilGPT-2 on one (train, validation) split.\n",
    "    Returns the validation loss for this fold.\n",
    "    \"\"\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir = f\"./fold_{fold_id}\",   # distinct directory per fold\n",
    "        num_train_epochs = 10,\n",
    "        per_device_train_batch_size = 2,\n",
    "        logging_strategy=\"epoch\",\n",
    "        eval_strategy = \"epoch\",\n",
    "        seed = 42,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model = model,\n",
    "        args = args,\n",
    "        train_dataset = train_ds,\n",
    "        eval_dataset = val_ds,\n",
    "        data_collator = data_collator,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    return metrics[\"eval_loss\"]\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5. Training with K-Fold Cross-Validation\n",
    "# ----------------------------------------\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "indices = np.arange(len(tokenized_dataset[\"train\"]))\n",
    "\n",
    "losses = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(indices)):\n",
    "    train_ds = tokenized_dataset[\"train\"].select(train_idx.tolist())\n",
    "    val_ds   = tokenized_dataset[\"train\"].select(val_idx.tolist())\n",
    "\n",
    "    loss = train_one_fold(train_ds, val_ds, fold)\n",
    "    losses.append(loss)\n",
    "    print(f\"Fold {fold+1}/{k}  •  val_loss = {loss:.4f}\")\n",
    "\n",
    "print(\"\\nCross-validated loss:\",\n",
    "      np.mean(losses), \"±\", np.std(losses),\n",
    "      \"   (perplexity ≈\", math.exp(np.mean(losses)), \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16446810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:15, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.473900</td>\n",
       "      <td>2.981997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.860400</td>\n",
       "      <td>2.651104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.428200</td>\n",
       "      <td>2.434000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.181800</td>\n",
       "      <td>2.294168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.015100</td>\n",
       "      <td>2.205747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.795300</td>\n",
       "      <td>2.147324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.677500</td>\n",
       "      <td>2.109092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.620200</td>\n",
       "      <td>2.086211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.523100</td>\n",
       "      <td>2.072872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.501600</td>\n",
       "      <td>2.067855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=40, training_loss=2.1077220320701597, metrics={'train_runtime': 15.8664, 'train_samples_per_second': 5.042, 'train_steps_per_second': 2.521, 'total_flos': 2612967505920.0, 'train_loss': 2.1077220320701597, 'epoch': 10.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# 6. Final training on the entire dataset\n",
    "# ----------------------------------------\n",
    "\n",
    "# Create train and validation datasets from the original dataset and tokenize them\n",
    "final_dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "final_tokenized_dataset = final_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Define training arguments\n",
    "final_args = TrainingArguments(\n",
    "    output_dir = \"./distilgpt2-followup\",\n",
    "    num_train_epochs = 10,\n",
    "    per_device_train_batch_size = 2,\n",
    "    logging_steps = 10,\n",
    "    logging_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    seed = 42,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"eval_loss\",\n",
    "    greater_is_better = False,\n",
    "    learning_rate = 2e-5,\n",
    "    weight_decay = 0.01,\n",
    "    max_grad_norm = 1.0,\n",
    ")\n",
    "\n",
    "trainer_final = Trainer(\n",
    "    model = model,\n",
    "    args = final_args,\n",
    "    train_dataset = final_tokenized_dataset[\"train\"],\n",
    "    eval_dataset = final_tokenized_dataset[\"test\"],\n",
    "    data_collator = data_collator,\n",
    ")\n",
    "\n",
    "trainer_final.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1e0a7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./distilgpt2-followup/tokenizer_config.json',\n",
       " './distilgpt2-followup/special_tokens_map.json',\n",
       " './distilgpt2-followup/vocab.json',\n",
       " './distilgpt2-followup/merges.txt',\n",
       " './distilgpt2-followup/added_tokens.json',\n",
       " './distilgpt2-followup/tokenizer.json')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "# 7. Save the final model and tokenizer\n",
    "# -------------------------------------\n",
    "\n",
    "trainer_final.save_model(\"./distilgpt2-followup\")\n",
    "tokenizer.save_pretrained(\"./distilgpt2-followup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b71f6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statement: I volunteered at a local animal shelter yesterday.\n",
      "Follow-Up: What inspired you to volunteer at a local animal shelter?\n",
      "\n",
      "Statement: I went hiking in the mountains last weekend.\n",
      "Follow-Up: What inspired you to hike there?\n",
      "\n",
      "Statement: I started reading a new book about the history of art.\n",
      "Follow-Up: What inspired you to start learning art?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 8. Prep for user examples\n",
    "# -------------------------\n",
    "\n",
    "import re\n",
    "\n",
    "model_dir = \"./distilgpt2-followup\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model     = AutoModelForCausalLM.from_pretrained(model_dir)\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=trainer_final.model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=60,\n",
    "    min_length=20,\n",
    "    early_stopping=True,\n",
    "    num_beams=5,            # ← search 5 beams in parallel\n",
    "    length_penalty=1.2,     # ← slightly favor longer sequences\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p=0.9, \n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "def ask_follow_up(statement: str) -> str:\n",
    "    prompt = f\"Statement: {statement}\\nFollow-Up:\"\n",
    "    out = generator(prompt, num_return_sequences=1)[0][\"generated_text\"]\n",
    "    parts = re.split(r\"Follow-Up:?\\s*\", out)\n",
    "    return parts[-1].strip()\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# 9. Test out the model with a few examples\n",
    "# -----------------------------------------\n",
    "statements = [\n",
    "    \"I volunteered at a local animal shelter yesterday.\",\n",
    "    \"I went hiking in the mountains last weekend.\",\n",
    "    \"I started reading a new book about the history of art.\"\n",
    "]\n",
    "\n",
    "for statement in statements:\n",
    "    print(f\"Statement: {statement}\")\n",
    "    print(f\"Follow-Up: {ask_follow_up(statement)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b79ae00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Get input from user\\nuser_input = input(\"Enter your statement: \")\\n\\n# Generate and display a follow-up question\\nfollow_up = ask_follow_up(user_input)\\nprint(\"Suggested follow-up question:\", follow_up)\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# 10. Uncomment and run the following block to test with user input\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "# Get input from user\n",
    "user_input = input(\"Enter your statement: \")\n",
    "\n",
    "# Generate and display a follow-up question\n",
    "follow_up = ask_follow_up(user_input)\n",
    "print(\"Suggested follow-up question:\", follow_up)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
